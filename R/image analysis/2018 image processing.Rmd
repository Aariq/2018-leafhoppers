---
title: "2018 Leaf Scan Analysis"
output: html_notebook
---

Date initiated: 2019-05-06
Date compiled: `r Sys.Date()`
```{r message=FALSE, warning=FALSE}
library(here)
library(tidyverse)
library(glue)
```

**Goal:**

This document contains notes about doing the image analysis.

# Choose random images for training set

First, copy a random subset of files to use as a training set.

## 2018

```{r eval=FALSE}
# scandir <- "/Users/scottericr/Box/Image Analysis/2018/Leaf Scans/Manipulative" #change to network drive?
leaves <- list.files(scandir, recursive = TRUE, pattern = "leaf.+\\.png", full.names = FALSE)
length(leaves)

# make a tibble of all the paths to images
df <- tibble(path = leaves)
# mutate to make paths for where to copy
df <- df %>%
  mutate(cultivar = str_extract(path, "^[^/]+(?=/)"),
         scan = str_extract(path, "(?<=/).+(?=/)"),
         leaf = str_extract(path, "[^/]+(?=.png)")) %>% 
  mutate(new.filename = glue("{scan}_{leaf}.png"),
         from.path = glue("{scandir}/{path}"),
         to.path = glue("{scandir}/Training Sample/{new.filename}"))

## Take a random sample of rows
# runif(1, 1, 1000)
set.seed(688)
train <- df %>% group_by(cultivar) %>% sample_n(15) %>% ungroup()

# Copy them into a training set folder
# file.copy(from = train$from.path, to = train$to.path) #DO NOT UNCOMMENT THIS.  THE ACTUAL TEST SET DOESN"T MATCH THESE FILES.  I MUST HAVE CHANGED THE SEED OR SOMETHING BY ACCIDENT.
```

I opened all the images in FIJI and converted them to a stack.  I filled in any black resulting from different image sizes by hand with the fill tool using a color that matches the background.

## 2017

```{r eval=FALSE}
# scandir2017 <- "/Users/scottericr/Box/Image Analysis/2017/Manipulative/Manipulative Experiment Leaf Scans"
scandir2017 <- "/Volumes/as_rsch_orianslab_tea01$/Image Analysis/2017/Manipulative/Manipulative Experiment Leaf Scans"
leaves2 <- list.files(scandir2017, recursive = TRUE, pattern = ".+\\.png", full.names = FALSE)
df2 <- tibble(path = leaves2)

df2 <- df2 %>%
  mutate(plant = str_extract(path, "^[^/]+(?=/)"),
         file = str_extract(path, "[^/]+(?=.png)")) %>% 
  mutate(from.path = glue("{scandir2017}/{path}"),
         to.path = glue("{scandir2017}/Training Sample/{file}.png"))

# runif(1, 1, 1000)
set.seed(2)

train2017 <- df2 %>% sample_n(30)
train2017

# file.copy(from = train2017$from.path, to = train2017$to.path)
```


# Training the classifier

I trained the classifier using these images with the following settings:

Training features:

- Hessian
- Sobel
- Variance
- Minimum
- Median
- Anisotropic
- Bilateral

With a minimum sigma of 2 and a maximum of 16

These settings gave the lowest out of bag error.  The training set included some folded leaves and some dead leaves, which I might eventually exclude from the final data, but I think that's ok.

I saved the data and classifier as `full_stack_classifier.model` and `full_stack_data.arff`.

This was repeated for both 2017 and 2018 separately.

I loaded these into the WEKA experimenter and saved the experiment as `full_stack_experiment.exp`.  I loaded the explorer and found kappa = 0.996 for the 2018 data.  However, this is using the classifier on the training set.  I need to make a test set to do this properly

## Making a test set.
To properly test the performance of the classifier, I need to test it on images that weren't in the training set.

```{r eval=FALSE}
set.seed(509)
test_set <-
  df %>%
  # filter(!to.path %in% train_set) %>%
  filter(!str_detect(path, "Training")) %>%   #exclude training samples
  group_by(cultivar) %>% 
  sample_n(5) %>%  #get 5 from each CV to test classifier on
  ungroup() %>% 
  mutate(to.path = str_replace(to.path, "Training Sample", "Test Sample"))
# test_set

# file.copy(from = test_set$from.path, to = test_set$to.path)

test_set2 <-
  df2 %>% 
  filter(!to.path %in% train2017$to.path) %>% 
  sample_n(10) %>% 
  mutate(to.path = str_replace(to.path, "Training Sample", "Test Sample"))

# file.copy(from = test_set2$from.path, to = test_set2$to.path)
```

After adding ROIs to these images as if I were training a new classifier, I saved the data as `test_data.arff`.  I could then open this up in the Weka experimenter and use the trained classifier on it.  This gives a kappa of 0.998 ± 0.001 for the 2018 data and 0.985 ± 0.002 for the 2017 data.

# Applying the classifier
## Image curation

First I dealt with folded leaves.  If the leaf margins were folded back, I did nothing.  If they were folded forward, so as to obscure some of the underside of the leaf, I used a paint tool to erase the overlapping section.  I also edited out petioles and obvious particles of dirt, dead insects, or broken leaves.  Some leaves were completely excluded, for example if they were facing the wrong direction (upper side of leaf) or had a lot of shadows or dirt on them obscuring the leaf color.


To apply the classifier to a folder of images, I used a beanshell script found in the Weka manual, reproduced below

```{javascript}
// @File(label="Input directory", description="Select the directory with input images", style="directory") inputDir
// @File(label="Output directory", description="Select the output directory", style="directory") outputDir
// @File(label="Weka model", description="Select the Weka model to apply") modelPath
// @String(label="Result mode",choices={"Labels","Probabilities"}) resultMode
 
import trainableSegmentation.WekaSegmentation;
import trainableSegmentation.utils.Utils;
import ij.io.FileSaver;
import ij.IJ;
import ij.ImagePlus;

// starting time
startTime = System.currentTimeMillis();
  
// caculate probabilities?
getProbs = resultMode.equals( "Probabilities" );
 
// create segmentator
segmentator = new WekaSegmentation();
// load classifier
segmentator.loadClassifier( modelPath.getCanonicalPath() );
  
// get list of input images
listOfFiles = inputDir.listFiles();
for ( i = 0; i < listOfFiles.length; i++ )
{
    // process only files (do not go into sub-folders)
    if( listOfFiles[ i ].isFile() )
    {
        // try to read file as image
        image = IJ.openImage( listOfFiles[i].getCanonicalPath() );
        if( image != null )
        {                   
            // apply classifier and get results (0 indicates number of threads is auto-detected)
            result = segmentator.applyClassifier( image, 0, getProbs );
 
            if( !getProbs )
                // assign same LUT as in GUI
                result.setLut( Utils.getGoldenAngleLUT() );
             
            // save result as TIFF in output folder
            outputFileName = listOfFiles[ i ].getName().replaceFirst("[.][^.]+$", "") + ".tif";
            new FileSaver( result ).saveAsTiff( outputDir.getPath() + File.separator + outputFileName );
  
            // force garbage collection (important for large images)
            result = null; 
            image = null;
            System.gc();
        }
    }
}
// print elapsed time
estimatedTime = System.currentTimeMillis() - startTime;
IJ.log( "** Finished processing folder in " + estimatedTime + " ms **" );
```

# Getting results
The script above creates the results images, but to get data in a tabular form, I used an ImageJ macro that Michelle Mu helped write:

```{javascript}
//ImageJ macro for exporting numerical results from classified images
inpath = getDirectory("Analyzed Images");

//get file names
files = getFileList(inpath);
for(n = 0; n < lengthOf(files); n++){
	print(files[n]);
}

category = newArray("damaged", "undamaged", "background")
for(j = 0; j < lengthOf(files); j++){ //loop through files
    open(files[j]);
    title = getTitle();
    getStatistics(area, mean, min, max, std, histogram); //this gets the number of pixels

    //add a column to results table
    for (i=0; i<3; i++) { //just do the first three rows in the histogram, corresponding to three colors of classified image
            setResult("Category", i, category[i]);
            setResult(title, i, histogram[i]); //adds a column for each file
    }   
	close(); //close the image before opening a new one
}
saveAs("results", inpath + "//results.txt"); //saves results table as text file
run("Clear Results");
```


This produces a results.txt file with columns that have the image file name and rows for damaged, undamaged, and background pixel counts.  The file names are just "leaf 1.tif", "leaf 2.tif", etc. and do not contain info about the sample or cultivar.  That info is in the containing folder.

So, I think what I need to do is:

1. ~~read in results.txt~~
2. ~~append column headings with folder name~~
3. ~~gather~~
4. ~~spread~~
5. ~~rowbind everything~~
6. ~~separate cultivar, sample # and leaf #~~
7. ~~merge sample #'s where there is an "a" and a "b" (because not all the leaves fit in one scan originally)~~
8. calculate leaf area in mm^2 (need a conversion for this.  hmm...I'm pretty sure I remembered to scan a ruler at some point)
8. ~~calculate % damage~~
9. summarize by sample
10. add columns for twister leaf on each plant
11. export!

## Read in results.txt's

```{r}
jgy_path <- "/Volumes/as_rsch_orianslab_tea01$/Image Analysis/2018/Leaf Scans/Manipulative/Jin Guan Yin"
lj_path <- "/Volumes/as_rsch_orianslab_tea01$/Image Analysis/2018/Leaf Scans/Manipulative/Longjing"
q_path <- "/Volumes/as_rsch_orianslab_tea01$/Image Analysis/2017/Manipulative/Manipulative Experiment Leaf Scans"

#need to do the 2017 data separately since filenames are a little different.
filenames_2018 <- list.files(c(jgy_path, lj_path), recursive = TRUE, "results.txt", full.names = FALSE)
paths_2018 <- list.files(c(jgy_path, lj_path), recursive = TRUE, "results.txt", full.names = TRUE)

filenames_2017 <- list.files(q_path, recursive = TRUE, "results.txt", full.names = FALSE)
paths_2017 <- list.files(q_path, recursive = TRUE, "results.txt", full.names = TRUE)

dflist_2018 <-
  map(paths_2018, read_tsv) %>%
  set_names(str_extract(filenames_2018, ".+(?=/results/)"))

dflist_2017 <- 
  map(paths_2017, read_tsv) %>% 
  set_names(paste0("Q", str_extract(filenames_2017, ".+(?=/results/)")))
```

## Wrangle

```{r}
raw_2018 <- map2_dfr(.x = dflist_2018, .y = names(dflist_2018), ~{
  .x %>%
    select(-matches("X1")) %>% #remove column X1 if it exists
    rename_at(vars(-matches("Category")), .funs = list(~paste(.y, .))) %>% 
    gather(-Category, key = filename, value = pixels) %>% 
    spread(key = Category, value = pixels) 
})  %>% 
  separate(filename, into = c("plant", "trash", "leaf")) %>% 
  select(-trash) %>% 
  mutate(cultivar = str_extract(plant, "\\D"),
         leaf_area_px = undamaged + damaged,
         #leaf_area_mm2 = leaf_area_px * ?????,
         percent_damage = damaged/leaf_area_px * 100) %>% 
  select(cultivar, plant, leaf, everything())

raw_2017 <- map2_dfr(.x = dflist_2017, .y = names(dflist_2017), ~{
  .x %>% 
    select(-matches("X1")) %>% 
    gather(-Category, key = filename, value = pixels) %>% 
    spread(key = Category, value = pixels)
}) %>% 
  separate(filename, into = c("trash", "plant", "trash2", "leaf")) %>% 
  select(-trash, -trash2) %>% 
  add_column(cultivar = "Q") %>% 
  mutate(leaf_area_px = undamaged + damaged,
         # leaf_area_mm2 = leaf_area_px * ????,
         percent_damage = damaged/leaf_area_px * 100) %>% 
  select(cultivar, plant, leaf, everything())
```

Next, combine a's and b's---multiple scans of same plant.  I think the easiest way to do this is to just remove the letter from the plant ID and move it to the leaf #

```{r}
results_2018 <-
  raw_2018 %>% 
  mutate(leaf = case_when(str_detect(plant, "a$") & leaf != "T" ~ paste0(leaf, "a"),
                          str_detect(plant, "b$") & leaf != "T" ~ paste0(leaf, "b"),
                          TRUE ~ leaf),
         plant = str_remove(plant, "[a-b]$"))

results_2017 <- raw_2017

write_rds(results_2018, here('data', 'cleaned', '2018_leaf_damage.rds'))
write_rds(results_2017, here('data', 'cleaned', '2017_leaf_damage_new.rds'))
```



# Summarize and combine with treatment info

These data will be more useful if I summarize them by plant (mean damage, twister leaf damage, n leaves) and combine with treatment info (leafhopper density treatment, before and after density) to make for easier merging with other datasets.

```{r}
twister_leaf_2018 <-
  results_2018 %>%
  filter(leaf == "T") %>%
  select(cultivar, plant, twister_damage = percent_damage)

summary_2018 <-
  results_2018 %>% 
  group_by(cultivar, plant) %>% 
  summarize(mean_leaf_area_px = mean(leaf_area_px),
            mean_percent_damage = mean(percent_damage),
            n_leaves = n()) %>% 
  left_join(twister_leaf_2018)

twister_leaf_2017 <-
  results_2017 %>% 
  filter(leaf == "T") %>% 
  select(cultivar, plant, twister_damage = percent_damage)

summary_2017 <-
  results_2017 %>% 
  group_by(cultivar, plant) %>% 
  summarize(mean_leaf_area_px = mean(leaf_area_px),
            mean_percent_damage = mean(percent_damage),
            n_leaves = n()) %>% 
  left_join(twister_leaf_2017)
```

read in treatment data to merge

```{r}
treatment_2018_raw <- readxl::read_excel(here('data', 'raw', '2018 density experiment.xlsx')) %>%
  janitor::clean_names()

treatment_2018 <- 
  treatment_2018_raw %>% 
  mutate(final_number_of_leafhoppers = as.numeric(final_number_of_leafhoppers)) %>% 
  mutate(cultivar = str_extract(cultivar, "^."),
         plant = paste0(cultivar, bag_id),
         density_start = initial_number_of_leafhoppers/number_shoots,
         density_end = final_number_of_leafhoppers/number_shoots) %>% 
  select(cultivar, plant, density_treatment, density_start, density_end)

treatment_data_2018 <- left_join(summary_2018, treatment_2018)

```

```{r}
treatment_2017_raw <- read_csv(here('data', 'raw', '2017 manipulative experiment treatment data.csv')) %>% 
  janitor::clean_names()

treatment_2017 <- 
  treatment_2017_raw %>% 
  add_column(cultivar = "Q") %>% 
  # mutate(plant = paste0(cultivar, plant)) %>% 
  mutate(density_start = leafhoppers_start/leaves,
         density_end = leafhoppers_end/leaves) %>% 
  select(cultivar, plant, density_treatment = density, density_start, density_end) %>% 
  filter(!is.na(density_treatment)) %>% 
  replace_na(list(density_start = 0, density_end = 0))

treatment_data_2017 <- left_join(summary_2017, treatment_2017)
```

```{r}
write_rds(treatment_data_2018, here('data', 'cleaned', '2018_treatment_data.rds'))
write_rds(treatment_data_2017, here('data', 'cleaned', '2017_treatment_data.rds'))
```


---
title: "2017 Leafhopper GCMS analysis"
author: "Eric R. Scott"
date: "2019-08-01"
output: 
  html_notebook: 
    highlight: kate
    theme: yeti
    toc: yes
    toc_float: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Last compiled: `r Sys.Date()`*

```{r packages, include=FALSE}
library(tidyverse)
library(here)
library(readxl)
#for RDA:
library(vegan)
library(RVAideMemoire)
#for figures:
library(cowplot)
```

# Purpose

What is the goal of this notebook?

# Load Data
Read in cleaned GCMS data (which includes leafhopper density already) and leafhopper damage data (from image analysis)

```{r data, echo=TRUE}
gc_wide <- read_rds(here("data", "cleaned", "2017_gcms_wide.rds"))
gc_tidy <- read_rds(here("data", "cleaned", "2017_gcms_tidy.rds"))
gc_wide.zeroes <- read_rds(here("data", "cleaned", "2017_gcms_zeroes.rds"))
```

```{r}
annotations <- read_excel(here("data", "cleaned", "Compound annotation updated.xlsx")) %>% rename(compound = Compound)
```


## Data Dictionary

`gc_tidy`: A tidy dataframe of all the chemistry and other data

- `sample`: Sample name
- `cultivar`: In this year, all plants were Qing Xin Da Mao, but I included this column for uniformity with the 2018 experiment.
- `density_start`: The density of leafhoppers applied at the start of the experiment in **insects/young leaf**
- `density_end`: Ending density in **insects/young leaf** 
- `mean_percent_damage`: Percentage of damaged pixels averaged across all leaves for that sample
- `twister_damage`: Percentage of damaged pixels for the leaf the volatiles were sampled from.
- `No.`: Compound number.  This comes from the Ion Analytics methods file.
- `Compound`: Compound name
- `RPA`: Relative peak area
- `rt`: retention time, in minutes
- `ri`: retention index
- `present`: logical. Was the compound detected in a particular sample?

`gc_wide`: A wide version with columns for each `Compound` with `RPA` as the value


# Data pre-treatment
Most data pre-treatment was done in the wrangling Rmd. I already determine that log transformation followed by scaling is probably a good idea to improve normality.  However, the data is still zero-inflated, so it might be better to just use a distance based approach instead, which I think is "nonparametric".  Maybe it doesnt' really matter though since the permuation test for the RDA is nonparametric anyway.

```{r}
#attribute stripper function
rm_attr <- function(x){
  attributes(x) <- NULL
  return(x)
  }

#columns that aren't compound RPAs
metavars <- c("sample", "cultivar", "density_start", "density_end", "mean_percent_damage", "twister_damage")
```
 

```{r}
gc_wide.logscale <- 
  gc_wide %>% 
  mutate_at(vars(-metavars), log) %>%
  mutate_at(vars(-metavars), scale) %>%
  #strip atrributes left by scale() that interfere with some other functions down the road
  mutate_at(vars(-metavars), rm_attr)

gc_wide.zeroes <- 
  gc_wide.zeroes %>% 
  mutate_at(vars(-metavars), scale) %>% 
  mutate_at(vars(-metavars), rm_attr)
```

I may also want to log-transform the percent leaf damage data, but I can do that ad-hoc later.

```{r}
ggplot(gc_wide.logscale, aes(log(mean_percent_damage))) + geom_histogram(bins = 7)
```


# Analysis

## Descriptive statistics
1. how many compounds total?
94
```{r}
gc_tidy %>% group_by(sample) %>% tally()
```

2. how many compounds are found in all samples?
Only 4
```{r}
gc_tidy %>% 
  group_by(Compound) %>% 
  summarize(nsample = sum(present)) %>% 
  filter(nsample > 18) %>% 
  rename(compound = Compound) %>%
  left_join(annotations)

```


## PLS for density

```{r}
library(ropls)
library(chemhelper)
```
```{r}
pls_dens <- opls(gc_wide.logscale %>% select(-metavars), gc_wide.logscale$density_end,
                 plotL = FALSE)
get_VIP(pls_dens) %>% arrange(desc(VIP))
```


## RDA for density
### Fit RDA model

Only analysis for the regular RDA is shown, because the distance-based RDA gave the same results and you can't get loadings from it.

```{r}
#scaled, transformed
rda_dens <-
  rda(gc_wide.logscale %>% select(-metavars) ~ density_end,
      data = gc_wide.logscale)

#distance based on unscaled, untransformed data.
dbrda_dens <-
  dbrda(gc_wide.zeroes %>% select(-metavars) ~ density_end,
      data = gc_wide.zeroes)
```

### How much total variance does the experimental design explain?

```{r}
MVA.synt(rda_dens)
# MVA.synt(dbrda_dens)
```

yeesh, only 9.12% explained by ending density
29.24% using the distance-based model with untransformed data.  BUT, I think this is wrong.

### ANOVA
3. Test for significance that this amount of explained variance is higher than the null hypothesis of no effect of the experimental design:

```{r}
anova(rda_dens)
# anova(dbrda_dens)
```

Significant effect of ending density on leaf volatiles

4. Then we test for significance of individual factors and interaction terms:

```{r}
MVA.anova(rda_dens)
# MVA.anova(dbrda_dens)
```

### Loadings / Correlations

I need to extract loadings, then figure out which compounds are signifcantly correlated with RDA axis, **not** with leafhopper density.  Should be correlation of scores with data.

```{r}
# MVA.scores(dbrda_dens)
scores <- MVA.scores(rda_dens)$coord
loads <- MVA.load(rda_dens)$loads %>% rename(loading = `Constr. comp. 1`)

data <- gc_wide.logscale %>% select(-metavars)

dens_biomarkers <-
  map_df(data, ~cor.test(.x, scores[["Constr. comp. 1"]]) %>% broom::glance(), .id = "compound") %>%
  bind_cols(loads) %>%
  mutate(p.adj = p.adjust(p.value, "fdr")) %>% 
  filter(p.adj < 0.05) %>%
  select(compound, loading, correlation = estimate, p.value, p.adj) %>% 
  arrange(desc(abs(loading)))
```



## PLS for damage
```{r}
pls_dam <- opls(gc_wide.logscale %>% select(-metavars), gc_wide.logscale$twister_damage,
                plotL = FALSE)
get_VIP(pls_dam) %>% arrange(desc(VIP))
```

I think I actually like RDA better because it tells you explicitly how much variation the experimental design accounts for.  Gives an idea of how much background variation there is.  Good discussion points.

## RDA for damage
### Fit RDA

```{r}
rda_dam <- 
  rda(gc_wide.logscale %>% select(-metavars) ~ twister_damage,
      data = gc_wide.logscale)

dbrda_dam <- 
  dbrda(gc_wide.zeroes %>% select(-metavars) ~ twister_damage,
      data = gc_wide.zeroes, distance = "euclidean")
```

### How much total variance does the experimental design explain?

```{r}
MVA.synt(rda_dam)
# MVA.synt(dbrda_dam)
```
Twister leaf damage explains 8% of variation in loged scaled volatiles. 
8.33% if I use a distance-based RDA
### ANOVA
3. Test for significance that this amount of explained variance is higher than the null hypothesis of no effect of the experimental design:

```{r}
anova(rda_dam)
```
Marginally significant

4. Then we test for significance of individual factors and interaction terms:

```{r}
MVA.anova(rda_dam)
```

### Loadings / Correlations

```{r}
scores <- MVA.scores(rda_dam)$coord
loads <- MVA.load(rda_dam)$loads %>% rename(loading = `Constr. comp. 1`)

data <- gc_wide.logscale %>% select(-metavars)


dam_biomarkers <-
  map_df(data, ~cor.test(.x, scores[["Constr. comp. 1"]]) %>% broom::glance(), .id = "compound") %>%
  bind_cols(loads) %>%
  mutate(p.adj = p.adjust(p.value, "fdr")) %>% 
  filter(p.adj < 0.05) %>%
  select(compound, loading, correlation = estimate, p.value, p.adj) %>% 
  arrange(desc(abs(loading)))
# dam_biomarkers
```

# Biomarker Table

Join data from both response variables

```{r}
dens_biomarkers <- left_join(dens_biomarkers, annotations)
dam_biomarkers <- left_join(dam_biomarkers, annotations)
biomarker_tab <-
  bind_rows(
  dens_biomarkers %>% add_column(response = "Density"),
  dam_biomarkers %>% add_column(response = "Damage")
) %>% 
  mutate_all(~na_if(.,"NA")) %>% #replace text NAs with actual NAs
  mutate(`Chemical Family` = snakecase::to_sentence_case(`Chemical Family`)) %>% 
  mutate_at(vars(loading, p.adj), round, 3) %>% 
  select(Compound = `Pretty Name`, CAS, "RDA Loading" = loading, p = p.adj, Aroma, `Chemical Family`, response)
biomarker_tab
```

write to CSV for formatting in Numbers / Excel

```{r}
write_excel_csv(biomarker_tab, here("figs", "2017 biomarkers.csv"), na = "-")
```

## Univariate plots

```{r}
# dens_data <- gc_tidy %>% filter(Compound %in% pull(dens_biomarkers, compound))

dens_data <-
  left_join(dens_biomarkers, gc_tidy) %>% 
  mutate(`Pretty Name` = fct_reorder(`Pretty Name`, abs(loading), .desc = TRUE))


dens_plot <-
  ggplot(dens_data, aes(x = density_end, y = RPA)) +
  geom_point() +
  facet_wrap(~`Pretty Name`, scales = "free_y") +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "Leafhopper density (insects / young leaf)",
       y = "Relative peak area")
dens_plot
```

```{r}
save_plot(here("figs", "density-biomarkers.png"), dens_plot,
          ncol = 4,
          nrow = 4, 
          base_height = 2,
          base_asp = 1.3)
```


## Univariate plots

Here, I should plot these biomarkers and look for thresholds/non-linear patterns.

```{r}
dam_data <-
  left_join(dam_biomarkers, gc_tidy) %>% 
  mutate(`Pretty Name` = fct_reorder(`Pretty Name`, abs(loading), .desc = TRUE))

dam_plot <-
  ggplot(dam_data, aes(x = twister_damage, y = RPA)) +
  geom_point() +
  facet_wrap(~`Pretty Name`, scale = "free_y") +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "% Damage to DCSE focal leaf",
       y = "Relative peak area")
dam_plot
```

```{r}
save_plot(here("figs", "damage-biomarkers.png"), dam_plot,
          ncol = 3,
          nrow = 2,
          base_height = 2,
          base_asp = 1.3)
```

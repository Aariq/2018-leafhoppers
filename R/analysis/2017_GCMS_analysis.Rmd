---
title: "2017 Leafhopper GCMS analysis"
author: "Eric R. Scott"
date: "2019-08-01"
output: 
  html_notebook: 
    highlight: kate
    theme: yeti
    toc: yes
    toc_float: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Last compiled: `r Sys.Date()`*

```{r packages, include=FALSE}
library(tidyverse)
library(here)
#for RDA:
library(vegan)
library(RVAideMemoire)

# library(ropls)
# library(chemhelper) #for get_VIP
```

# Purpose

What is the goal of this notebook?

# Load Data
Read in cleaned GCMS data (which includes leafhopper density already) and leafhopper damage data (from image analysis)

```{r data, echo=TRUE}
gc_wide <- read_rds(here("data", "cleaned", "2017_gcms_wide.rds"))
gc_tidy <- read_rds(here("data", "cleaned", "2017_gcms_tidy.rds"))
gc_wide.zeroes <- read_rds(here("data", "cleaned", "2017_gcms_zeroes.rds"))
```

## Data Dictionary

`gc_tidy`: A tidy dataframe of all the chemistry and other data

- `sample`: Sample name
- `cultivar`: In this year, all plants were Qing Xin Da Mao, but I included this column for uniformity with the 2018 experiment.
- `density_start`: The density of leafhoppers applied at the start of the experiment in **insects/young leaf**
- `density_end`: Ending density in **insects/young leaf** 
- `mean_percent_damage`: Percentage of damaged pixels averaged across all leaves for that sample
- `twister_damage`: Percentage of damaged pixels for the leaf the volatiles were sampled from.
- `No.`: Compound number.  This comes from the Ion Analytics methods file.
- `Compound`: Compound name
- `RPA`: Relative peak area
- `rt`: retention time, in minutes
- `ri`: retention index
- `present`: logical. Was the compound detected in a particular sample?

`gc_wide`: A wide version with columns for each `Compound` with `RPA` as the value


# Data pre-treatment
Most data pre-treatment was done in the wrangling Rmd. I already determine that log transformation followed by scaling is probably a good idea to improve normality.  However, the data is still zero-inflated, so it might be better to just use a distance based approach instead, which I think is "nonparametric".  Maybe it doesnt' really matter though since the permuation test for the RDA is nonparametric anyway.

```{r}
#attribute stripper function
rm_attr <- function(x){
  attributes(x) <- NULL
  return(x)
  }

#columns that aren't compound RPAs
metavars <- c("sample", "cultivar", "density_start", "density_end", "mean_percent_damage", "twister_damage")
```
 

```{r}
gc_wide.logscale <- 
  gc_wide %>% 
  mutate_at(vars(-metavars), log) %>%
  mutate_at(vars(-metavars), scale) %>%
  #strip atrributes left by scale() that interfere with some other functions down the road
  mutate_at(vars(-metavars), rm_attr)

gc_wide.zeroes <- 
  gc_wide.zeroes %>% 
  mutate_at(vars(-metavars), scale) %>% 
  mutate_at(vars(-metavars), rm_attr)
```

I may also want to log-transform the percent leaf damage data, but I can do that ad-hoc later.

```{r}
ggplot(gc_wide.logscale, aes(log(mean_percent_damage))) + geom_histogram(bins = 7)
```


# Analysis


## RDA for density
1. Fit RDA model

Only analysis for the regular RDA is shown, because the distance-based RDA gave the same results and you can't get loadings from it.

```{r}
#scaled, transformed
rda_dens <-
  rda(gc_wide.logscale %>% select(-metavars) ~ density_end,
      data = gc_wide.logscale)

#distance based on unscaled, untransformed data.
dbrda_dens <-
  dbrda(gc_wide.zeroes %>% select(-metavars) ~ density_end,
      data = gc_wide.zeroes)
```

2. How much total variance does the experimental design explain?

```{r}
MVA.synt(rda_dens)
# MVA.synt(dbrda_dens)
```

yeesh, only 9.12% explained by ending density
29.24% using the distance-based model with untransformed data.  BUT, I think this is wrong.

3. Test for significance that this amount of explained variance is higher than the null hypothesis of no effect of the experimental design:

```{r}
anova(rda_dens)
# anova(dbrda_dens)
```

Significant effect of ending density on leaf volatiles

4. Then we test for significance of individual factors and interaction terms:

```{r}
MVA.anova(rda_dens)
# MVA.anova(dbrda_dens)
```

5. Loadings / Correlations

I need to extract loadings, then figure out which compounds are signifcantly correlated with RDA axis, **not** with leafhopper density.  Should be correlation of scores with data.

```{r}
# MVA.scores(dbrda_dens)

scores <- MVA.scores(rda_dens)$coord
loads <- MVA.load(rda_dens)$loads %>% rename(loading = `Constr. comp. 1`)

data <- gc_wide.logscale %>% select(-metavars)


map_df(data, ~cor.test(.x, scores[["Constr. comp. 1"]]) %>% broom::glance(), .id = "compound") %>%
  bind_cols(loads) %>%
  mutate(p.adj = p.adjust(p.value, "fdr")) %>% 
  filter(p.adj < 0.05) %>%
  select(compound, loading, correlation = estimate, p.value, p.adj) %>% 
  arrange(desc(abs(loading)))
```

## Univariate plots
Here, I should plot these biomarkers and look for thresholds/non-linear patterns.


## RDA for damage
1. Fit RDA

```{r}
rda_dam <- 
  rda(gc_wide.logscale %>% select(-metavars) ~ twister_damage,
      data = gc_wide.logscale)

dbrda_dam <- 
  dbrda(gc_wide.zeroes %>% select(-metavars) ~ twister_damage,
      data = gc_wide.zeroes, distance = "euclidean")
```

2. How much total variance does the experimental design explain?

```{r}
MVA.synt(rda_dam)
# MVA.synt(dbrda_dam)
```
Twister leaf damage explains 8% of variation in loged scaled volatiles. 
8.33% if I use a distance-based RDA

3. Test for significance that this amount of explained variance is higher than the null hypothesis of no effect of the experimental design:

```{r}
anova(rda_dam)
```
Marginally significant

4. Then we test for significance of individual factors and interaction terms:

```{r}
MVA.anova(rda_dam)
```

5. Loadings / Correlations

```{r}
scores <- MVA.scores(rda_dam)$coord
loads <- MVA.load(rda_dam)$loads %>% rename(loading = `Constr. comp. 1`)

data <- gc_wide.logscale %>% select(-metavars)


map_df(data, ~cor.test(.x, scores[["Constr. comp. 1"]]) %>% broom::glance(), .id = "compound") %>%
  bind_cols(loads) %>%
  mutate(p.adj = p.adjust(p.value, "fdr")) %>% 
  filter(p.adj < 0.05) %>%
  select(compound, loading, correlation = estimate, p.value, p.adj) %>% 
  arrange(desc(abs(loading)))
```

## Univariate plots
Here, I should plot these biomarkers and look for thresholds/non-linear patterns.

# Annotating biomarkers

Create a table with biomarkers annotated with flavor percepts and ontologies

## Flavor percepts

I'm going with these top 6 VIPs that have VIP > 1 but also have a significant p-value from a correlation.

```{r}
# method <-
#   read_IA(here("Method File Construction", "BACE_MS-Subtraction Compound References.csv")) %>%
#   select(Compound, CAS)
# VIPtable <- 
#   left_join(VIPtable %>% filter(VIP>2), method)
# VIPtable <- VIPtable %>% 
#   mutate(percept = fn_percept(as.cas(CAS))) %>% 
#   #manually insert flavor percepts for dehydroxy linalool oxide from FooDB.ca
#   mutate(percept = ifelse(CAS == "54750708", "green, herbal, minty, phenolic, rosemary, spice", percept))
# VIPtable
```

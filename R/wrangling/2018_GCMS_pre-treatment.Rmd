---
title: "2018 GCMS pre-treatment"
author: Eric R. Scott
date: "2019-07-31"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
    highlight: kate
    theme: yeti
---
```{r setup}
knitr::opts_chunk$set(
	echo = TRUE
)
```
*Last compiled: `r Sys.Date()`*
# Packages

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(chemhelper)
library(here)
library(webchem)

#for outlier detection:
library(MVN)
library(HDoutliers)
library(ropls)

#resolve conflicts
map <- purrr::map 
mvn <- MVN::mvn
```
# Workflow Overview

1. Tag 0's as nondetects
2. Tag 0<Area<1000 as censored
3. Filter out known contaminants
4. Calculate RPA
5. Split data into samples and method blank
6. Subtract RPAs of method blank

This will give you sample data with 0s and possibly negative values for RPA and flags for nondetects and peaks that should be censored.

7. Remove compounds that are not found in more than 2 samples (at least 3 samples) with RPA > 0
8. Set RPA for nondetects, censored, and all RPA <= 0  to 500/IS
9. Check for and remove any obvious outliers
10. Create wide dataframe

# Read in Data

## All the exported integration files

Need to be connected to network drive for this to work!

```{r}
Data.dir <- "/Volumes/as_rsch_orianslab_tea01$/IonAnalytics/IonAnalytics Projects/Shengzhou_2018/Data"

if(!dir.exists(Data.dir)) {
  stop("Gotta connect to the network drive!")
}

files <- dir(Data.dir,
             pattern = "Shengzhou_adj Integration Report.csv",
             full.names = TRUE, #adds full path
             recursive = TRUE) #drills down in directory structure

filenames <- str_extract(files, "(?<=/)[^/]+(?=/[^/]+$)")
# samples <- str_extract(filenames, "(?<=Hop_).+(?=\\.D)")
gc_tidy <- files %>%
  map(read_IA) %>%
  set_names(filenames) %>% 
  bind_rows(.id = "filename") %>% 
  rename(area = `Area [a.u.*s]`,
         rt = `R.Time [min.]`)
gc_tidy
```

## Alkane files
Read and wrangle

```{r}
alkanes1 <- read_IA("/Volumes/as_rsch_orianslab_tea01$/IonAnalytics/IonAnalytics Projects/Shengzhou_2018/Data/073018_alkanemix/Meth_073018_alkanemix Integration Report.csv")
alkanes_lj <-
  alkanes1 %>% 
  slice(1:19) %>%  #that's enough I think.
  mutate(rt = ifelse(`R.Time [min.]` == 0, `Expect. [min.]`, `R.Time [min.]`)) %>% 
  select(Compound, rt) %>% 
  add_column(C_num = 6:24)


alkanes2 <- read_IA("/Volumes/as_rsch_orianslab_tea01$/IonAnalytics/IonAnalytics Projects/Shengzhou_2018/Data/082018_Alkane/Meth_073018_alkanemix Integration Report.csv")
alkanes_jgy <- 
  alkanes2 %>% 
  slice(1:19) %>% 
  mutate(rt = ifelse(`R.Time [min.]` == 0, `Expect. [min.]`, `R.Time [min.]`)) %>% 
  select(Compound, rt) %>% 
  add_column(C_num = 6:24)
```

## Method file with CAS numbers
Even though there are technically two methods, they have the same compounds, so I should be able to get what I need from just one

```{r}
method <- read_IA("/Volumes/as_rsch_orianslab_tea01$/IonAnalytics/IonAnalytics Projects/Shengzhou_2018/Methods/Shengzhou_adj_JGY/Shengzhou_adj Compound References.csv")
```

Merge with data

```{r}
CASs <-
  method %>%
  select(Compound, CAS) %>% 
  mutate(CAS = str_remove_all(CAS, "-")) %>% 
  mutate(CAS = as.cas(CAS)) %>% 
  #try to catch all the unknowns
  mutate(CAS = ifelse(str_detect(Compound, "^\\d+$") | str_detect(Compound, "DCSE"), NA, CAS))
# CASs %>% filter(Compound == "1,4-Pentadiene")

gc_tidy <-
  left_join(gc_tidy, CASs) %>% select(filename, No., Type, Compound, CAS, everything())
```


## Extract cultivar and sample name from filename
I think jinguanyin blank20 is actually not a blank

```{r}
gc_tidy <-
  gc_tidy %>% 
  mutate(filename = str_remove(filename, ".D$")) %>% # for some reason one file has a .D at the end.
  mutate(filename = str_replace(filename, "Blank20", "Bag20")) %>% #pretty sure it's not a blank
  mutate(cultivar = case_when(str_detect(filename, "Longjing") ~ "L",
                              str_detect(filename, "Jin") ~ "J",
                              TRUE ~ as.character(NA)), #shouldn't be any NAs, but just in case
         plant_num = as.character(as.integer(str_extract(filename, "\\d+$"))), #blanks will be NA
         sample = paste0(cultivar, plant_num)) %>% 
  select(filename, cultivar, plant_num, sample, everything())
```


# Tag non-detects and to-be-censored

```{r}
gc_tidy <-
  gc_tidy %>%
  mutate(ND = area == 0,
         Censor = area > 0 & area < 1000)
```


# Remove known contaminants and problematic peaks
Contaminants:

- Propanoic acid, 2-methyl-, 1-(1, 1-dimethylethyl)-2methyl-1, 3-propanediyl ester (from nitrile gloves)
- Toluene (very large peak, seems unlikely that it is a natural product)

These chlorinated compounds are likely pesticides:

- Benzaldehyde, 2,6-dichloro-
- Benzene, chloro-


```{r}
contaminants <- c("Propanoic acid, 2-methyl-, 1-(1,1-dimethylethyl)-2-methyl-1,3-propanediyl ester",
                  "Toluene",
                  "Benzyl chloride",
                  "Benzene, chloro-",
                  "Benzaldehyde, 2,6-dichloro-",
                  "141")

# gc_tidy %>% filter(Compound %in% contaminants) %>% count(filename)
gc_tidy.1 <-
  gc_tidy %>%
  filter(!Compound %in% contaminants) %>%
  filter(No. > 91)
```

# Calculate RPA

Two files have abnormally low values for the peak area of the internal standard.  I'll replace with the average of other files in that cultivar.

I also noticed here that JGY and LJ cultivars internal standard peak areas are more than an order of magnitude different.  I probably should be cautios about comparing cultivars

```{r}
#extract napthalene D8 area
gc_IS <-
  gc_tidy.1 %>% 
  filter(Compound == "Naphthalene-D8") %>%
  rename(IS = area) %>% 
  select(filename, cultivar, IS)

gc_IS %>% filter(IS < 100000)
# JGY 11 and JGY 4

JGY_IS_MEAN <- 
  gc_IS %>%
  filter(IS > 100000, cultivar == "J") %>%
  pull(IS) %>%
  mean()

# Replace bad IS areas with mean for cultivar.
gc_IS <- 
  gc_IS %>%
  group_by(cultivar) %>%
  mutate(IS = ifelse(IS < 100000, JGY_IS_MEAN, IS))

#join with gc.tidy and mutate to calculate RPA
gc_tidy.2 <- full_join(gc_tidy.1, gc_IS)
gc_tidy.2 <- gc_tidy.2 %>% 
  mutate(RPA = area/IS) %>% 
  #don't need Naphtalene-D8 anymore
  filter(Compound != "Naphthalene-D8")
# gc_tidy.2 %>% filter(str_detect(filename, "Jin")) %>% count(filename)
```

# Field blank subtraction

I have two field blanks, one for each cultivar

```{r}
gc_tidy.3 <- 
  gc_tidy.2 %>% 
  #split by cultivar
  group_by(cultivar) %>% 
  group_split() %>% 
  # for each cultivar extract the blanks and join them to the data minus the blanks
  purrr::map(~{
    blank <- filter(., str_detect(filename, "[b,B]lank")) %>% 
      rename(background = RPA) %>% 
      select(Compound, background)
    gc <- filter(., !str_detect(filename, "[b,B]lank"))
    left_join(gc, blank)
  }) %>% 
  # recombine cultivars
  bind_rows()
```

I'm literally subtracting the blank.  The alternative is Nicole's method: if RPA > background then keep it as is, if RPA <= background, set to zero.

```{r}
gc_tidy.4 <- gc_tidy.3 %>% 
  mutate(RPA = RPA-background)
gc_tidy.4
```


# Read in leafhopper density and damage data and join

```{r}
treatments <- read_rds(here('data', 'cleaned', '2018_treatment_data.rds'))
gc_tidy.5 <- left_join(gc_tidy.4, treatments)
```

# Calculate Retention Indices

```{r}
gc_tidy.6 <-
  gc_tidy.5 %>% 
  mutate(ri = case_when(cultivar == "J" ~ calc_RI(rt, alkanes_jgy$rt, alkanes_jgy$C_num),
                        cultivar == "L" ~ calc_RI(rt, alkanes_lj$rt, alkanes_lj$C_num)))
```


# Deal with non-detects, censored peaks, and other zeros and negative values

Nondetects were zeros to begin with, not found by IonAnalytics at all.  Censored peaks are those with peak area < 1000.  According to the Robbat lab, areas < 1000 are not accurate due to being below the LOD.  There are multiple options for dealing with this, but they usually set those peaks to zero.  There may be other RPA values <= 0 due to subtracting the method blank.

I'll set all zeroes to 500/IS.  This will be useful for log-transforming data since log(0) = -inf. I also add a "present" column that will be useful for getting compound counts and such later on.


Also set Q-values of compounds not found to NA

```{r}
gc_tidy.7 <-
  gc_tidy.6 %>%
  mutate(RPA = case_when(ND           ~ 500/IS,
                         Censor       ~ 500/IS,
                         RPA <=500/IS ~ 500/IS, #if after background subtraction peak areas < 500
                         TRUE    ~ RPA),
         present = case_when(ND      ~ FALSE,
                             Censor  ~ FALSE,
                             RPA <=0 ~ FALSE,
                             TRUE    ~ TRUE)) %>%
  mutate(QVal = ifelse(present, QVal, NA)) %>% 
  select(sample, cultivar, density_start, density_end, mean_percent_damage, twister_damage, No., Compound, CAS, RPA, QVal, rt, ri, present)

#How many compounds detected in each sample?
gc_tidy.7 %>%
  group_by(sample) %>%
  summarize(num_compounds = sum(present))
```

Preserve zeros for distance-based analyses:

```{r}
gc_zeroes <-
  gc_tidy.7 %>% 
  mutate(RPA = ifelse(present, RPA, 0))
```

# Remove rare peaks

Remove compounds that are found in 5 or fewer samples.

```{r}
gc_tidy.final <-
  gc_tidy.7 %>% 
  group_by(Compound) %>% #for each compound...
  filter(sum(present) >= 5) 
gc_tidy.final %>% ungroup() %>% count(sample) #326 compounds

gc_zeroes.final <-
  gc_zeroes %>% 
  group_by(Compound) %>% 
  filter(sum(present) >= 5)
gc_zeroes.final %>% ungroup() %>% count(sample) #just checking that it's the same
```

# Check for compounds with low average Q-value

I really don't super trust the Q-value anymore, but I think I'll go ahead and filter out anything with a Q-value less than 90.

```{r}
lowQs <-
  gc_tidy.final %>% 
  group_by(Compound) %>% 
  summarize(meanQ = mean(QVal, na.rm = TRUE)) %>% 
  arrange(meanQ) %>% 
  filter(meanQ <= 90) %>% 
  pull(Compound)

gc_tidy.final <- gc_tidy.final %>% filter(!Compound %in% lowQs)
```

# Create wide dataframe for multivariate analysis

Unfortunately changes column order to alphabetical.  This is fixed in `tidyr` 1.0 with the `pivot_wider()` function, but I don't think its so important that I need to use a development version of a package.

```{r}
gc_wide <- 
  gc_tidy.final %>%
  select(-rt, -ri, -No., -present, -CAS, -QVal) %>%
  spread(key = Compound, value = RPA)

gc_wide.zeroes <-
  gc_zeroes.final %>% 
  ungroup %>% 
  select(-rt, -ri, -No., -present, -CAS, -QVal) %>% 
  spread(key = Compound, value = RPA)
```

# Outlier detection
## Multivariate normality

For some reason (data too large? numbers too small?) the `mvn()` function often fails due to a singular matrix error.  Below, I've run it on random subsets of the data and log transformation seems to improve normality. Interestingly, scaling seems to make things worse.

```{r}
gc_tidy.final %>% 
  ggplot(aes(RPA)) + geom_histogram() + facet_wrap(~cultivar)
gc_tidy.final %>% 
  ggplot(aes(log(RPA))) + geom_histogram() +facet_wrap(~cultivar)
```
This may change once the data is finalized.

```{r}
metavars <- c("sample", "cultivar", "density_start", "density_end", "mean_percent_damage", "twister_damage")

```
 
```{r eval=FALSE}
# This code seems to hang.
# test <-
#   gc_tidy.final %>%
#   ungroup() %>% 
#   select(-rt, -ri, -No., -present, -CAS) %>% 
#   spread(key = Compound, value = RPA) %>% 
#   select(-metavars) %>%
#   # mutate_all(~.*1000) %>%
#   mvn(mvnTest = "mardia",
#       transform = "log",
#       multivariatePlot = "qq",
#       scale = TRUE)
# test
```

## Multivariate outlier detection

Using Leland Wilkinson's algorithm from `HDoutliers`

```{r}
out <- HDoutliers(select(gc_wide, -metavars) , alpha = 0.1)
gc_wide[out, ]

#after log transformation
out2 <- HDoutliers(select(gc_wide, -metavars) %>% mutate_all(log), alpha = 0.1)
gc_wide[out2, ]
```
L15 and L21 detected as outliers in log-transformed data only, and at alpha = 0.1, not alpha = 0.05

## With PCA

```{r}
pca <- opls(select(gc_wide, -metavars)%>% mutate_all(log) , plotL = FALSE, predI = 2)
plot(pca, parLabVc = gc_wide$sample)
```

L15 is maybe an extreme value, but not worth removing.



# Write to file

I think all I'm going to need is the tidy version with the `present` column and the wide version.  I can do any data transformations in the analysis script.

```{r}
write_rds(gc_tidy.final, here('data', 'cleaned', '2018_gcms_tidy.rds'))
write_rds(gc_wide, here('data', 'cleaned', '2018_gcms_wide.rds'))
write_rds(gc_wide.zeroes, here("data", "cleaned", "2018_gcms_zeroes.rds"))
```





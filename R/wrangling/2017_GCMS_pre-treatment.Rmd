---
title: "GC Data Wrangling and Pre-processing"
output: html_notebook
---

Date initialized: 2018-04-30
Date compiled: `r Sys.Date()`

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse) #for data manipulation
library(stringr) #for functions to deal with strings
library(here)
library(forcats)
library(chemhelper)
library(gglabeller)
library(cowplot)
```


# Workflow Overview

1. Tag 0's as nondetects
2. Tag 0<Area<1000 as censored
3. Filter out known contaminants
4. Calculate RPA
5. Split data into samples and method blank
6. Subtract RPAs of method blank

This will give you sample data with 0s and possibly negative values for RPA and flags for nondetects and peaks that should be censored.

7. Remove compounds that are not found in more than 2 samples (at least 3 samples) with RPA > 0
8a. Set RPA for nondetects, censored, and all RPA <= 0  to 1/IS
8b. Set RPA for nondetects, censored, and all RPA < 0 to 0 (for venn diagram)
9. Check for and remove any obvious outliers
10. Create wide dataframes from 8a and 8b.

# Read in files

```{r directories}
#this is the directory that contains data files loaded into the project already
Data.dir <- "/Volumes/as_rsch_orianslab_tea01$/IonAnalytics/IonAnalytics Projects/Fujian 2017 Manipulative/Data"

if(!dir.exists(Data.dir)) {
  stop("Gotta connect to the network drive!")
}

files <- dir(Data.dir,
             pattern = "Fujian Manipulative Adjusted2 Integration Report.csv",
             full.names = TRUE, #adds full path
             recursive = TRUE) #drills down in directory structure

filenames <- str_extract(files, "(?<=/)[^/]+(?=/[^/]+$)")
# samples <- str_extract(filenames, "(?<=Hop_).+(?=\\.D)")
gc_tidy <- files %>%
  map(read_IA) %>%
  set_names(filenames) %>% 
  bind_rows(.id = "filename") %>% 
  rename(area = `Area [a.u.*s]`,
         rt = `R.Time [min.]`)

```
## Alkane Files
TODO

## Extract sample name from filename, set cultivar

```{r}
gc_tidy <- 
  gc_tidy %>% 
  mutate(cultivar = "Q",
         plant_num = str_extract(filename, "(?<=Hop_)\\d+(?=_)"), #blanks will be NA
         sample = ifelse(!is.na(plant_num), paste0(cultivar, plant_num), filename)) %>% 
  select(filename, cultivar, plant_num, sample, everything())
  
```



# Tag non-detects and to-be-censored

```{r}
gc_tidy <-
  gc_tidy %>%
  mutate(ND = area == 0,
         Censor = area > 0 & area < 1000)
```

# Remove known contaminants and problematic peaks
Contaminants:

- Propanoic acid, 2-methyl-, 1-(1, 1-dimethylethyl)-2methyl-1, 3-propanediyl ester (from nitrile gloves)
- Toluene (very large peak, seems unlikely that it is a natural product)

These chlorinated compounds are likely pesticides:

- Benzaldehyde, 2,6-dichloro-
- Benzene, chloro-

These compounds should be removed for other reasons:

- 141: Unknown that shows up in method blanks.  Nicole doesn't know what it is, but is pretty sure it is contaminant.
- Anything with an RT earlier than 3.3-ish (currently corresponds to No. > 91)

Problematic peaks includes peaks that I decided were bad, and should be marked as "not found" in all files, but was too lazy to go through and mark in Ion Analytics.  It's much easier to just exclude them in R.

 - (135) Heptane, 2,4-dimethyl-: Check all.  Bad peak, borderline Q value.
 - (181) 1 (DCSE): Hitting same peak as (180) Pentane, 1-nitro-.  Mark all as not found.  Remove from method when done with deconvolution so it doesn't get propogated to the next dataset.
 - (234) 37: Pretty bad peak.  Mark all as not found?
 - (268, 269): unknown 64 = limonene? Mark 64 as not found.
 - (329) 2-Nonanone: Bad peak.  Mark all as not found
 - (345) Fenchol<endo->: Bad peak.  Mark all as not found
 - (408) 158: Matches a few other peaks.  Mark all as not found
 - (419) 127: one ion low.  mark all as not found. Consider removing from method (could be decanal + noise?)
 - (554) Geranylacetone: Hits same peak as (556) 5,9-Undecadien-2-one...  Mark all as not found.

```{r}
contaminants <- c("Propanoic acid, 2-methyl-, 1-(1,1-dimethylethyl)-2-methyl-1,3-propanediyl ester",
                  "Toluene",
                  "Benzyl chloride",
                  "Benzene, chloro-",
                  "Benzaldehyde, 2,6-dichloro-",
                  "141")

problematic <- c(135, 181, 234, 268, 329, 345, 408, 419, 554)
gc_tidy.1 <- gc_tidy %>%
  filter(!Compound %in% contaminants) %>%
  filter(No. > 91) %>% 
  filter(!No. %in% problematic)
```

# Manually check low Q-value compounds
One last check for problematic peaks.

```{r}
gc_tidy.1 %>% 
  filter(QVal < 90 & !ND & !Censor) %>%
  arrange(sample, QVal)
```

# Calculate RPA

```{r}
#extract napthalene D8 area
gc_IS <- gc_tidy.1 %>% 
  filter(Compound == "Naphthalene-D8") %>%
  rename(IS = area) %>% 
  select(sample, IS)

#join with gc.tidy and mutate to calculate RPA
gc_tidy.2 <- full_join(gc_tidy.1, gc_IS)
gc_tidy.2 <- gc_tidy.2 %>% 
  mutate(RPA = area/IS) %>% 
  #don't need Naphtalene-D8 anymore
  filter(Compound != "Naphthalene-D8")
gc_tidy.2
```

# Method blank subtraction

I have two method blanks, one from the beginning and one from the end.  I could average them and subtract from all samples or subtract the start blank from the start samples and the end blank from the end samples.

For now, I'm just using the end data, so I'll just use the end blank.

```{r}
#split into samples and background
gc_blank <-
  gc_tidy.2 %>%
  filter(str_detect(filename,"blank_end"))
gc_tidy.3 <-
  gc_tidy.2 %>% 
  filter(!str_detect(filename, "blank"))

#subtract background
gc_blank.1 <-
  gc_blank %>%
  rename(background = RPA) %>% 
  select(Compound, background)

gc_tidy.3 <- left_join(gc_tidy.3, gc_blank.1)

gc_tidy.4 <-
  gc_tidy.3 %>%
  mutate(RPA = RPA - background)
```

# Remove rare peaks

Remove compounds that are found in 3 or fewer samples.

```{r}
gc_tidy.5 <-
  gc_tidy.4 %>% 
  group_by(Compound) %>% #for each compound...
  filter(sum(RPA > 0) >= 3)
```


# Read in treatment data and join

```{r}
treatments <- read_rds(here('data', 'cleaned', '2017_treatment_data.rds'))
```


```{r}
gc_tidy.6 <- left_join(gc_tidy.5, treatments)
```


# Deal with non-detects, censored peaks, and other zeros and negative values

Nondetects were zeros to begin with, not found by IonAnalytics at all.  Censored peaks are those with peak area < 1000.  According to the Robbat lab, areas < 1000 are not accurate due to being below the LOD.  There are multiple options for dealing with this, but they usually set those peaks to zero.  There may be other RPA values <= 0 due to subtracting the method blank.

I want to deal with these values in two ways:

1. Set them all to zero.  This will be useful for calculating numbers of compounds detected in various samples and for making venn diagrams.

2. Set them all to 1/IS.  This will be useful for log-transforming data since log(0) = -inf.

On second thought, I think all I need is a tidy dataset with zeroes set to 1/IS and a column for present or not

```{r}
gc_tidy.final <-
  gc_tidy.6 %>%
  mutate(RPA = case_when(ND      ~ 1/IS,
                         Censor  ~ 1/IS,
                         RPA <=0 ~ 1/IS,
                         TRUE    ~ RPA),
         present = case_when(ND      ~ FALSE,
                             Censor  ~ FALSE,
                             RPA <=0 ~ FALSE,
                             TRUE    ~ TRUE)) %>%
  select(sample, cultivar, density_start, density_end, mean_percent_damage, twister_damage, No., Compound, RPA, rt, present)

#How many compounds detected in each sample?
gc_tidy.final %>%
  group_by(sample) %>%
  summarize(num_compounds = sum(present))
```

# Create wide data frame

```{r}
gc_wide <- 
  gc_tidy.final %>%
  ungroup() %>% 
  select(-rt, -No., -present) %>%
  spread(key = Compound, value = RPA)
```


# Preliminary Data Analysis

I'll use a combination of univariate scatterplots and PCA to check for outliers

## Univariate plots

### Prepare data
1. Order compounds by mean RPA so that when I break them into chunks, the scales will be more helpful
2. Slice data into chunks
3. Graph 'em with gglabeller and select potential outliers

```{r}
plot_data <-
  gc_tidy.final %>%
  ungroup() %>% 
  mutate(shortname = as.factor(str_trunc(Compound, 12))) %>%
  mutate(shortname = fct_reorder(Compound, RPA, mean)) %>% 
  mutate(group = as.numeric(shortname) %>%
           cut(6) %>%
           as.integer()) %>% 
  split(.$group)
#must explicitly drop unused factors or gglabeller won't work
plot_data <- map(plot_data, ~ select(., -group) %>% mutate(shortname = fct_drop(shortname))) 
```

### Label plots

```{r eval=FALSE}
plots <- map(plot_data,
    ~ggplot(., aes(y = RPA, x = shortname, color = density_end, label = sample)) +
     geom_point() +
      coord_flip() +
      scale_x_discrete(drop = FALSE) +
      theme_bw()
)
plots.labeled <- map(plots, gglabeller)
plots.labeled
```

Sample Q8 shows up a lot as an extreme value.

## Preliminary PCA

```{r}
metavars <- c("sample", "cultivar", "density_start", "density_end", "mean_percent_damage", "twister_damage")
library(ropls)
pca.1 <- opls(select(gc_wide, -metavars), scaleC = "standard")
pca.2 <-
  gc_wide %>%
  select(-metavars) %>%
  mutate_all(log) %>%
  opls(scaleC = "standard")

plot(pca.2, parLabVc = gc_wide$sample)
plot(pca.1, parLabVc = gc_wide$sample) #log transformed
```

log transformation makes PCA worse? Either way, 8_end is definitely a major outlier

# Remove Outliers

```{r}
outliers <- c("Q8")
pca.3 <-
  gc_wide %>%
  filter(!sample %in% outliers) %>%
  select(-metavars) %>%
  opls(scaleC = "standard", plotL = FALSE, printL = FALSE)

pca.4 <-
  gc_wide %>%
  filter(!sample %in% outliers) %>%
  select(-metavars) %>% 
  mutate_all(log) %>%
  opls(scaleC = "standard", plotL = FALSE, printL = FALSE)

plot(pca.3, parLabVc = gc_wide %>% filter(!sample %in% outliers) %>% .$sample)
plot(pca.4, parLabVc = gc_wide %>% filter(!sample %in% outliers) %>% .$sample)
```

No, log improves I think.

Remove outlier:

```{r}
gc_wide <- gc_wide %>% filter(!sample %in% outliers) 
gc_tidy.final <- gc_tidy.final %>% filter(!sample %in% outliers) 
```


# Write to file

```{r}
write_rds(gc_wide, here("data", "cleaned", "2017_gcms_wide.rds"))
write_rds(gc_tidy.final, here("data", "cleaned", "2017_gcms_tidy.rds"))
```
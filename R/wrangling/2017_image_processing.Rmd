---
title: "Leaf Image Analysis"
output: html_notebook
---

# 1. Create individual leaf images
This was done manually using Preview

# 2. Create image stacks
I created stacks of no more than 5 images.
This was done using the following image J macro:
```{javascript}
dir = getDirectory("choose a folder");

list = getFileList(dir);
nstacks = -floor(-list.length/5);
print(nstacks);
stacksize = round(list.length/nstacks);

//for each stack:
for(n=0; n<nstacks; n++){
	//open the first set of files
	files = Array.slice(list, stacksize*(n), stacksize*(n+1));
	for (i=0; i<files.length; i++){
			open(files[i]);
		}
	run("Images to Stack", "method=[Copy (top-left)] name=Stack title=[] use");
	width = getWidth;
	height = getHeight;
	setColor("white");
	for (j=1; j<=nSlices; j++){
		setSlice(j);
		floodFill(width-1, height-1);
	}

	saveAs("tiff", dir + "/Stack_" + n + ".tif");
	close();
}
```
# 3. Select random leaves to train classifier
Unfortunately on this computer I can probably only train on a stack of ~5-7 images without running out of memory.  For now I'll use the classifier Michelle made

# 4. Classify
I used the classifier Michelle created from tieguanyin leaves.  I ran the WEKA segmentation plugin manually on each stack of leaf images and created several classified image stacks per plant.

# 5. Extract Data
I extracted the data using this ImageJ macro:
```{javascript}
dir = getDirectory("Plant");
files = getFileList(dir);

//open and concatenate original image stacks to get sample names
for(a=0; a<files.length; a++){
	if(startsWith(files[a], "Stack")){
		open(files[a]);
	}
}
run("Concatenate...", "all_open title=[All Leaves]");
//get slice names

label = newArray(nSlices);
for (i = 1; i<=nSlices; i++){
	setSlice(i);
	label[i-1] = getInfo("slice.label");
}
close();

//get results

for(b=0; b<files.length; b++){
	if(startsWith(files[b], "Classified")){
		open(files[b]);
		run("Stack to Images");
	}
}

run("Images to Stack", "method=[Copy (top-left)] name=Stack title=[] use");
setColor(198,118,255);
width = getWidth;
height = getHeight;
for (j=1; j<=nSlices; j++){
		setSlice(j);
		floodFill(width-1, height-1);
}
run("8-bit Color", "number=3");

category = newArray("damaged", "background", "undamaged");
for (n = 1; n <= nSlices; n++) { //loop through slices
        setSlice(n); //set which slice
        getStatistics(area, mean, min, max, std, histogram);
        for (j=0; j<3; j++) {
            setResult("Category", j, category[j]);
            setResult(label[n-1], j, histogram[j]); //adds a column for each slice called "Count[slicenumber]"
        }
}
saveAs("results", dir+"/results.txt"); //saves results table as text file
close();
run("Clear Results");
```

# 6. Read Data into R and Tidy
All the data is saved in files titled `results.txt`.  I'll read those in and use folder names as sample names when rowbinding it all together.
```{r}
library(tidyverse)
library(here)
```
```{r message=FALSE, warning=FALSE}
paths <- list.dirs(here("Manipulative Experiment Leaf Scans"), full.names = TRUE)[-1]
files <- paste0(paths, "/results.txt")

leafdamage <- map_dfr(files, ~read_tsv(.) %>%
          select(-X1) %>%
          gather(-Category, key = sample, value = pixels)) %>% 
  separate(sample, into = c("plant", "plant.num", "leaf", "leaf.num")) %>% 
  select(-plant, -leaf) %>% 
  spread(key = Category, value = pixels) %>% 
  select(-background) %>% 
  mutate(damage.percent = damaged/undamaged*100)
```

# 7. Write to .rds
```{r}
write_rds(leafdamage, here("cleaned_data", "leaf damage.rds"))
```

